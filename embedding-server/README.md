# ğŸ§  Local Embedding API Server (Multilingual)

A lightweight embedding generation server using FastAPI + SentenceTransformer, supporting Chinese, English, Malay and more â€” powered by `BAAI/bge-m3`.

## ğŸš€ Features

- `/embed`: generate embedding for a single string
- `/embed/batch`: generate embedding for multiple strings
- Support for GPU acceleration (CUDA) via Docker
- Docker-ready deployment

## ğŸ”§ Requirements

- Docker (with NVIDIA container runtime)
- Optional: Python 3.10+ for local dev

## âš™ï¸ Run with Docker (GPU)

```bash
docker build -t embed-server .
docker run --gpus all --env-file .env -p 8000:8000 embed-server
```

## ğŸ“¦ API Usage

### `POST /embed`
```json
{
  "input": "Saya suka makan nasi lemak"
}
```

### `POST /embed/batch`
```json
{
  "inputs": ["I like cats", "æˆ‘å–œæ¬¢çŒ«", "Saya suka kucing"]
}
```

## ğŸ“¤ Response

```json
{
  "embedding": [...],
  "dim": 384,
  "model": "BAAI/bge-m3"
}
```

## âœï¸ License

MIT
